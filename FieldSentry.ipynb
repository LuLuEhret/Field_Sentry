{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FieldSentry.py is a script that checks the status of the sensors, weather and screens of the installations\n",
    "from insolAPI.WebAPI import API\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "import pendulum as pdl\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import requests\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "from pytz import timezone\n",
    "import numpy as np\n",
    "import pytz\n",
    "import getpass\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "SHOW_PLOT = False\n",
    "\n",
    "\n",
    "list_sensor = [\n",
    "    \"PAR\",\n",
    "    \"IRRAD\",\n",
    "    \"GII\",\n",
    "    \"DNI\",\n",
    "    \"DHI\",\n",
    "    \"TEMP\",\n",
    "    \"HUMI\",\n",
    "    \"RAIN\",\n",
    "    \"RAIN_TYPE\",\n",
    "    \"RAIN_ACCUMULATED\",\n",
    "    \"WIND\",\n",
    "    \"WIND_DIR\",\n",
    "    \"VIRTUAL\",\n",
    "    \"LEAF_TEMP\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "dict_screen_mode = {\n",
    "    0: \"\",\n",
    "    1: \"Auto\",\n",
    "    2: \"Manual\",\n",
    "    3: \"Emergency\",\n",
    "    4: \"Protection\",\n",
    "    5: \"Demo\",\n",
    "    6: \"Remote\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def read_json_config():\n",
    "    \"\"\"\n",
    "    Read the config.json file and return the api key\n",
    "    Parameters and response: https://openweathermap.org/forecast5\n",
    "    \"\"\"\n",
    "    with open(\"config/config.json\") as f:\n",
    "        config_data = json.load(f)\n",
    "\n",
    "    installations = {}\n",
    "\n",
    "    # Iterate through locations\n",
    "    locations = config_data['locations']\n",
    "    for location in locations:\n",
    "        # Store details in a dictionary\n",
    "        location_details = {\n",
    "            'id': location['id'],\n",
    "            'name': location['name'],\n",
    "            'latitude': location['latitude'],\n",
    "            'longitude': location['longitude'],\n",
    "            'wind_threshold': location['wind_threshold'],\n",
    "            'high_temperature_threshold': location['high_temperature_threshold'],\n",
    "            'has_a_screen': location['has_a_screen'],\n",
    "        }\n",
    "        installations[location['name']] = location_details\n",
    "    return installations, [config_data['api_key'], config_data['api_url']]\n",
    "\n",
    "\n",
    "\n",
    "def format_timestamp(original_timestamp_str):\n",
    "    original_timestamp = datetime.datetime.strptime(original_timestamp_str, '%Y-%m-%d %H:%M:%S')\n",
    "    formatted_timestamp_str = original_timestamp.strftime('%Hh %d-%m-%Y')\n",
    "    return formatted_timestamp_str\n",
    "\n",
    "\n",
    "\n",
    "def format_timestamps_in_dict(input_dict):\n",
    "    formatted_dict = {}\n",
    "    for key, sub_dict in input_dict.items():\n",
    "        formatted_dict[key] = {}\n",
    "        for event, timestamps in sub_dict.items():\n",
    "            try:\n",
    "                formatted_timestamps = [format_timestamp(ts) for ts in timestamps]\n",
    "                formatted_dict[key][event] = formatted_timestamps\n",
    "            except:\n",
    "                formatted_dict[key][event] = timestamps\n",
    "                pass\n",
    "    return formatted_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_weather_forecast(dict_instal, api_data, city_name):\n",
    "    \"\"\"\n",
    "    Request the weather forecast for the next 2 days, every 3 hours\n",
    "    \"\"\"\n",
    "    params = {\"appid\": api_data[0], \"cnt\": \"20\", \"units\": \"metric\"}\n",
    "\n",
    "    params[\"lat\"] = dict_instal[city_name][\"latitude\"]\n",
    "    params[\"lon\"] = dict_instal[city_name][\"longitude\"]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(api_data[1], params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        update_request_count()\n",
    "        return data\n",
    "\n",
    "    except Exception as ex:\n",
    "        # print(f\" \\n Error: {ex}\")\n",
    "        #generate an empty dict to avoid errors\n",
    "        error_dict = {'list': [{'dt': 0,\n",
    "                    'main': {'temp': 0,\n",
    "                        'feels_like': 0,\n",
    "                        'temp_min': 0,\n",
    "                        'temp_max': 0,\n",
    "                        'pressure': 0,\n",
    "                        'sea_level': 0,\n",
    "                        'grnd_level': 0,\n",
    "                        'humidity': 0,\n",
    "                        'temp_kf': 0},\n",
    "                    'weather': [{'id': 0,\n",
    "                        'main': 'Rain',\n",
    "                        'description': 'light rain',\n",
    "                        'icon': '10d'}],\n",
    "                    'clouds': {'all': 0},\n",
    "                    'wind': {'speed': 0, 'deg': 0, 'gust': 0},\n",
    "                    'visibility': 0,\n",
    "                    'pop': 0,\n",
    "                    'rain': {'3h': 0},\n",
    "                    'sys': {'pod': 'd'},\n",
    "                    'dt_txt': '9999-01-01 00:00:00'}]}\n",
    "        return error_dict  # noqa: E501\n",
    "\n",
    "\n",
    "\n",
    "def plot_weather_forecast(weather_data, city_name):\n",
    "    \"\"\"\n",
    "    If called, plot the weather forecast for the next 2 days\n",
    "    \"\"\"\n",
    "    forecast_date = []\n",
    "    forecast_temp = []\n",
    "    forecast_snow = []\n",
    "    forecast_rain = []\n",
    "    forecast_wind = []\n",
    "    forecast_pop = []\n",
    "\n",
    "    for forecast in weather_data[\"list\"]:\n",
    "        forecast_date.append(forecast[\"dt_txt\"])\n",
    "        forecast_temp.append(forecast[\"main\"][\"temp\"])\n",
    "        forecast_wind.append(forecast[\"wind\"][\"speed\"])\n",
    "        forecast_pop.append(forecast[\"pop\"])\n",
    "        try:\n",
    "            forecast_snow.append(forecast[\"snow\"][\"3h\"])\n",
    "        except:\n",
    "            forecast_snow.append(0)\n",
    "        try:\n",
    "            forecast_rain.append(forecast[\"rain\"][\"3h\"])\n",
    "        except:\n",
    "            forecast_rain.append(0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast_date,\n",
    "            y=forecast_temp,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Temperature\",\n",
    "            line=dict(color=\"orange\", width=2),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast_date,\n",
    "            y=forecast_snow,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Snow\",\n",
    "            line=dict(color=\"lightblue\", width=2),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast_date,\n",
    "            y=forecast_rain,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Rain\",\n",
    "            line=dict(color=\"darkcyan\", width=2),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=forecast_date,\n",
    "            y=forecast_wind,\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Wind\",\n",
    "            line=dict(color=\"darkred\", width=2),\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=forecast_date,\n",
    "            y=forecast_pop,\n",
    "            name=\"Precipitation Probability\",\n",
    "            marker_color=\"lightgrey\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout for better visualization\n",
    "    fig.update_layout(\n",
    "        title=\"Weather Forecast for \" + city_name + \"\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Values\",\n",
    "        legend=dict(x=1, y=1, traceorder=\"normal\"),\n",
    "        # Background color of the entire graph area,\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor=\"rgba(0,0,0,0.1)\")\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor=\"rgba(0,0,0,0.1)\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "def alert_user(weather_data, dict_events):\n",
    "    \"\"\"\n",
    "    Set the threshold for the alerts, and which alerts to send\n",
    "    \"\"\"\n",
    "    alert_list = []\n",
    "    for forecast in weather_data[\"list\"]:\n",
    "        try:\n",
    "            if bool(forecast[\"snow\"][\"3h\"]):\n",
    "                alert_list.append(\"Snow fall\")\n",
    "                alert_list.append(forecast[\"dt_txt\"])\n",
    "        except:\n",
    "            pass\n",
    "        if forecast[\"wind\"][\"speed\"] > dict_events[\"wind_threshold\"]:\n",
    "            alert_list.append(\"Strong wind\")\n",
    "            alert_list.append(forecast[\"dt_txt\"])\n",
    "        if forecast[\"main\"][\"temp\"] > dict_events[\"high_temperature_threshold\"]:\n",
    "            alert_list.append(\"High temperature\")\n",
    "            alert_list.append(forecast[\"dt_txt\"])\n",
    "        #to add a new alert, add the condition here. Also need to change the main\n",
    "    # if forecast[\"dt\"] == 0:\n",
    "    #     print(\"\\nError: no weather data available\")\n",
    "    return alert_list\n",
    "\n",
    "\n",
    "\n",
    "def update_request_count():\n",
    "    \"\"\"\n",
    "    update the number of requests made to the API, and the number of requests made during the last hour\n",
    "    \"\"\"\n",
    "    file_name = \"reports/count_requests.csv\"\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_name):\n",
    "        # Read the last line and get the count\n",
    "        with open(file_name, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            if lines:\n",
    "                last_line = lines[-1].strip()\n",
    "                count = int(last_line.split(\",\")[1]) + 1\n",
    "            else:\n",
    "                count = 1\n",
    "            # add the number of requests made during the last hour\n",
    "            last_hour = datetime.datetime.now() - datetime.timedelta(hours=1)\n",
    "            count_last_hour = 1\n",
    "            for line in lines:\n",
    "                if (\n",
    "                    datetime.datetime.strptime(\n",
    "                        line.split(\",\")[4].strip(), \"%Y-%m-%d %H:%M:%S\"\n",
    "                    )\n",
    "                    >= last_hour\n",
    "                ):\n",
    "                    count_last_hour = count_last_hour + 1\n",
    "    else:\n",
    "        # If the file doesn't exist, create it and set count to 1\n",
    "        count = 1\n",
    "        count_last_hour = 1\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    with open(file_name, \"a\") as file:\n",
    "        file.write(f\"Total,{count},last hour,{count_last_hour},{timestamp}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def save_alerts_to_csv(df):\n",
    "    \"\"\"\n",
    "    update the csv file with the alerts\n",
    "    \"\"\"\n",
    "    df['Timestamp'] = datetime.datetime.now().strftime('%H:%M:%S %d-%m-%Y')\n",
    "\n",
    "    #replace \\n with a \",\"\n",
    "    df = df.replace('\\n', ', ', regex=True)\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    df = df[[cols[-1]] + cols[:-1]]\n",
    "\n",
    "\n",
    "    #check if the file exists\n",
    "    if not os.path.exists(\"reports/log_reports.csv\"):\n",
    "        df.to_csv(\"reports/log_reports.csv\", index=False, header=True) # add the header if the file doesn't exist\n",
    "    else:\n",
    "        df.to_csv(\"reports/log_reports.csv\", mode='a', header=False, index=False)\n",
    "        with open(\"reports/log_reports.csv\", \"a\") as file:\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def list_to_string(lst):\n",
    "    \"\"\"\n",
    "    Convert a list to a string, to be able to print it\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return \"\\n\".join(map(str, lst))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def process_screen_data(df):\n",
    "    \"\"\"\n",
    "    logics to process the screen data\n",
    "    \"\"\"\n",
    "    df = df[['screen_id', 'state', 'name']]\n",
    "    screen_names = df['name'].unique()\n",
    "    list_states = []\n",
    "    for screen_name in screen_names:\n",
    "        df_screen_tmp = df[df['name'] == screen_name]\n",
    "        df_screen_tmp = df.sort_index(ascending=False)\n",
    "        state = df_screen_tmp['state'][0]\n",
    "        if state != 1:\n",
    "            list_states.append(f\"{screen_name}: {dict_screen_mode[state]}\")\n",
    "    if screen_names.size == 0:\n",
    "        list_states.append(\"No logs for 2d+\")\n",
    "    return list_states\n",
    "\n",
    "\n",
    "\n",
    "def print_progress_bar(percentage, length=10):\n",
    "    # print(percentage)\n",
    "    if np.isnan(percentage):\n",
    "        percentage = 1\n",
    "    block = int(round(length * percentage))\n",
    "    progress = \"[\" + \"#\" * block + \"-\" * (length - block) + \"]\"\n",
    "    # print(f\"\\r{progress}\", end=\"\", flush=True)\n",
    "    return progress\n",
    "\n",
    "\n",
    "\n",
    "def last_logs(dict_instal, list_sensor, api):\n",
    "    time_args = dict(\n",
    "        start=pdl.yesterday().subtract(weeks=1).to_datetime_string(),\n",
    "        stop=(pdl.now()).to_datetime_string(),\n",
    "        timezone = timezone('Europe/Zurich')\n",
    "    )\n",
    "\n",
    "    logs_joined = {}\n",
    "    dict_list_theoretical = {}\n",
    "    unique_sensors = {}\n",
    "    logs_joined_unique = {}\n",
    "    last_log = {}\n",
    "    time_diff = {}\n",
    "    print(\"\\nCollecting data...\\n\")\n",
    "    for instal in tqdm(dict_instal):\n",
    "        logs_joined[instal] = {}\n",
    "        dict_list_theoretical[instal] = []\n",
    "        sensor_number = 0\n",
    "        if dict_instal[instal][\"id\"] == \"xx\":\n",
    "            continue\n",
    "        for sensor_type in api.SensorsTypes:\n",
    "            if str(sensor_type).split(\".\")[1] in list_sensor:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                    logs_joined[instal][list_sensor[sensor_number]] = api.get_sensor_channels_logs_joined(**time_args,sensor_type=sensor_type, install=dict_instal[instal][\"id\"])\n",
    "                    sensor_number += 1\n",
    "                    try:\n",
    "                        theoretical_sensor = api.get_sensor_channels(sensor_type=sensor_type, install=dict_instal[instal][\"id\"])\n",
    "                        theoretical_sensor = theoretical_sensor[theoretical_sensor[\"deleted_at\"].isna()].sensor_name.unique()\n",
    "                        dict_list_theoretical[instal].extend(theoretical_sensor)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    print(\"\\nProcessing data...\\n\")\n",
    "    for instal in dict_instal:\n",
    "        unique_sensors[instal] = []\n",
    "        time_diff[instal] = {}\n",
    "        for sensor_type in logs_joined[instal]:\n",
    "            try:\n",
    "                unique_sensors[instal].extend(logs_joined[instal][sensor_type][\"sensor_name\"].unique())\n",
    "            except :\n",
    "                pass\n",
    "        unique_sensors[instal] = list(set(unique_sensors[instal]))\n",
    "        logs_joined_unique[instal] = {}\n",
    "        for sensor_type in logs_joined[instal]:\n",
    "            for unique_sensor in unique_sensors[instal]:\n",
    "                try:\n",
    "                    if unique_sensor in logs_joined[instal][sensor_type][\"sensor_name\"].unique():\n",
    "                        logs_joined_unique[instal][unique_sensor] = logs_joined[instal][sensor_type].loc[logs_joined[instal][sensor_type][\"sensor_name\"] == unique_sensor]\n",
    "                        logs_joined_unique[instal][unique_sensor].index = logs_joined_unique[instal][unique_sensor].index.round('min')\n",
    "                        logs_joined_unique[instal][unique_sensor] = logs_joined_unique[instal][unique_sensor].loc[~logs_joined_unique[instal][unique_sensor].index.duplicated(keep='first')]\n",
    "                except :\n",
    "                    pass\n",
    "\n",
    "\n",
    "        for sensor in dict_list_theoretical[instal]:\n",
    "            try:\n",
    "                logs_joined_unique[instal][sensor] = logs_joined_unique[instal][sensor].dropna(subset=[logs_joined_unique[instal][sensor].columns[1]])\n",
    "                time_serie = logs_joined_unique[instal][sensor].index.tz_localize(None)\n",
    "                now = pd.to_datetime(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                now_serie = pd.Series(data=now, index=[now])\n",
    "\n",
    "                time_serie.to_series()\n",
    "                time_serie = pd.Series(time_serie)\n",
    "\n",
    "                series = [time_serie, now_serie]\n",
    "                time_series = pd.concat(series, ignore_index=True)\n",
    "                time_difference = time_series.diff()\n",
    "                time_difference = time_difference[time_difference > pd.Timedelta(minutes=2)].sum()\n",
    "                time_diff[instal][sensor] = time_difference\n",
    "            except:\n",
    "                time_diff[instal][sensor] = pd.NaT\n",
    "\n",
    "        last_log[instal] = {}\n",
    "        for sensor in dict_list_theoretical[instal]:\n",
    "            try:\n",
    "                last_log[instal][sensor] = logs_joined_unique[instal][sensor].index[-1].strftime(\"%Y-%m-%d %Hh%M\")\n",
    "            except:\n",
    "                last_log[instal][sensor] = \"> 1 week\"\n",
    "            try:\n",
    "                if logs_joined_unique[instal][sensor].index[-1] > pdl.now().subtract(minutes=10):\n",
    "                    last_log[instal][sensor] = \"Online\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    #make a df with the last log and the time difference for each sensor\n",
    "    dict_df = {}\n",
    "    for instal in last_log:\n",
    "        dict_df[instal] = pd.DataFrame.from_dict(last_log[instal], orient=\"index\", columns=[\"Last log\"])\n",
    "        dict_df[instal][\"Time offline (1w)\"] = dict_df[instal].index.map(time_diff[instal])\n",
    "        try:\n",
    "            dict_df[instal][\"% offline\"] = dict_df[instal][\"Time offline (1w)\"].apply(lambda x: print_progress_bar(x.total_seconds() / (7 * 24 * 60 * 60)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "    for instal, df in dict_df.items():\n",
    "        # Sort the DataFrame by the \"Last log\" column\n",
    "        df_sorted = df.sort_values(by=[\"Last log\", \"Time offline (1w)\"], ascending=[True, False])\n",
    "\n",
    "        print(f\"{instal}\")\n",
    "        table = tabulate(df_sorted, headers=\"keys\", tablefmt=\"psql\", showindex=True)\n",
    "        print(table)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        with open(\"reports/output.txt\", \"a\", encoding=\"utf-8\") as text_file:\n",
    "            text_file.write(f\"{instal}\\n\")\n",
    "            text_file.write(tabulate(df_sorted, headers=\"keys\", tablefmt=\"psql\", showindex=True))\n",
    "            text_file.write(\"\\n\\n\")\n",
    "    return logs_joined_unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "## Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HTTPSConnectionPool(host='api.insolight.ch', port=443): Max retries exceeded with url: /api/auth/login (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A56C161490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Not Connected to the API\n",
      "\n",
      "Exiting...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001A56C161490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.insolight.ch', port=443): Max retries exceeded with url: /api/auth/login (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A56C161490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     local_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 9\u001b[0m api \u001b[38;5;241m=\u001b[39m \u001b[43mAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPI_user\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAPI_pwd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m api\u001b[38;5;241m.\u001b[39mget_sensor_channels(sensor_type\u001b[38;5;241m=\u001b[39mapi\u001b[38;5;241m.\u001b[39mSensorsTypes\u001b[38;5;241m.\u001b[39mTEMP, install\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\insolAPI\\WebAPI.py:247\u001b[0m, in \u001b[0;36mAPI.__init__\u001b[1;34m(self, email, passwd, install, dev_space, base_address)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m passwd:\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauth/login\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memail\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasswd\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\insolAPI\\WebAPI.py:266\u001b[0m, in \u001b[0;36mAPI.act\u001b[1;34m(self, act_type, path, refresh, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mact_type\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 266\u001b[0m resp: requests\u001b[38;5;241m.\u001b[39mResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_address\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mapi/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Manually as there can be\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\requests\\sessions.py:635\u001b[0m, in \u001b[0;36mSession.post\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Insolight\\mambaforge\\envs\\insolinsights\\Lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.insolight.ch', port=443): Max retries exceeded with url: /api/auth/login (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001A56C161490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     15\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m---> 16\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:2097\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2095\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2096\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2097\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1171\u001b[0m ):\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1064\u001b[0m )\n\u001b[0;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"config/api_credits_path.json\") as f:\n",
    "        installation_path = json.load(f)[\"path\"]\n",
    "\n",
    "    # installation_path = \"C:/Users/Insolight/Desktop/InsolReports/Installations/\"\n",
    "    with open(installation_path + \"local.json\") as f:\n",
    "        local_data = json.load(f)\n",
    "\n",
    "    api = API(local_data[\"API_user\"], local_data[\"API_pwd\"], dev_space=False)\n",
    "    api.get_sensor_channels(sensor_type=api.SensorsTypes.TEMP, install=23)\n",
    "    print(\"✅ Successfully connected to the API\\nCollecting data...\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ {e}\\nNot Connected to the API\")\n",
    "    print(\"\\nExiting...\")\n",
    "    sys.stdout.flush()\n",
    "    sys.exit(0)\n",
    "\n",
    "time_args = dict(\n",
    "start=pdl.now().subtract(days=0, hours=0, minutes=30).to_datetime_string(),\n",
    "stop=pdl.now().subtract(days=0, hours=0).to_datetime_string(),\n",
    "timezone=timezone('Europe/Zurich'),\n",
    ")\n",
    "time_args_screens = dict(\n",
    "    start=pdl.now().subtract(days=2, hours=2, minutes=30).to_datetime_string(),\n",
    "    stop=pdl.now().subtract(days=0, hours=2).to_datetime_string(),\n",
    "    timezone=timezone('Europe/Zurich'),\n",
    ")\n",
    "\n",
    "# declarations of the dictionaries\n",
    "dict_instal_json, api_data = read_json_config()\n",
    "dict_instal_logs = {}  # type: dict\n",
    "dict_sensor_channel_id = {}  # type: dict\n",
    "diff_logs = {}  # type: dict\n",
    "dict_logs_joined = {}  # type: dict\n",
    "dict_channel_id = {}  # type: dict\n",
    "dict_missing_sensors = {}  # type: dict\n",
    "dict_weather_data = {} # type: dict\n",
    "dict_alerts = {} # type: dict\n",
    "dict_time_of_snow = {} # type: dict\n",
    "dict_time_of_wind = {} # type: dict\n",
    "dict_time_high_T = {} # type: dict\n",
    "dict_alert_time = {} # type: dict\n",
    "dict_screen_states = {} # type: dict\n",
    "\n",
    "#main loop\n",
    "for instal in tqdm(dict_instal_json):\n",
    "    list_channel_id = [] # type: list\n",
    "    list_sensor_logging = [] # type: list\n",
    "    dict_logs_joined[instal] = {}\n",
    "    dict_sensor_channel_id[instal] = {}\n",
    "    sensor_number = 0\n",
    "    dict_alert_time[instal] = {\"Snow fall\": [], \"Strong wind\": [], \"High temperature\": []}\n",
    "    list_snow_time = []\n",
    "    list_wind_time = []\n",
    "    list_highT_time = []\n",
    "    dict_df_screen = {}\n",
    "    list_screen_states = []\n",
    "    diff_logs[instal] = []\n",
    "    dict_screen_states[instal] = []\n",
    "\n",
    "\n",
    "    # get the weather forecast for each installation\n",
    "    dict_weather_data[instal] = get_weather_forecast(dict_instal_json, api_data, instal)\n",
    "    if SHOW_PLOT:\n",
    "        plot_weather_forecast(dict_weather_data[instal], instal)\n",
    "    dict_alerts[instal] = alert_user(dict_weather_data[instal], dict_instal_json[instal])\n",
    "\n",
    "    for i in range(0, len(dict_alerts[instal]), 2):\n",
    "        if dict_alerts[instal][i] == \"Snow fall\":\n",
    "            list_snow_time.append(dict_alerts[instal][i + 1])\n",
    "            dict_alert_time[instal][\"Snow fall\"].append(dict_alerts[instal][i + 1])\n",
    "        if dict_alerts[instal][i] == \"Strong wind\":\n",
    "            list_wind_time.append(dict_alerts[instal][i + 1])\n",
    "            dict_alert_time[instal][\"Strong wind\"].append(dict_alerts[instal][i + 1])\n",
    "        if dict_alerts[instal][i] == \"High temperature\":\n",
    "            list_highT_time.append(dict_alerts[instal][i + 1])\n",
    "            dict_alert_time[instal][\"High temperature\"] = dict_alerts[instal][i + 1]\n",
    "\n",
    "    if dict_instal_json[instal][\"id\"] == 'xx':\n",
    "        continue\n",
    "\n",
    "\n",
    "    #screen data\n",
    "    if dict_instal_json[instal][\"has_a_screen\"]:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            dict_df_screen[instal] = api.get_screens_logs_joined(**time_args_screens, install=dict_instal_json[instal][\"id\"])\n",
    "            list_screen_states = process_screen_data(dict_df_screen[instal])\n",
    "    dict_screen_states[instal] = list_screen_states\n",
    "\n",
    "\n",
    "    # get all the sensors and channels for each installation\n",
    "    for sensor_type in api.SensorsTypes:\n",
    "        if str(sensor_type).split(\".\")[1] in list_sensor:\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "                    dict_logs_joined[instal][\n",
    "                        list_sensor[sensor_number]\n",
    "                    ] = api.get_sensor_channels_logs_joined(\n",
    "                        **time_args,\n",
    "                        sensor_type=sensor_type,\n",
    "                        install=dict_instal_json[instal][\"id\"],\n",
    "                    )\n",
    "                    list_sensor_logging.extend(\n",
    "                        dict_logs_joined[instal][\n",
    "                            list_sensor[sensor_number]\n",
    "                        ].sensor_channel_id.unique()\n",
    "                    )\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "                    dict_sensor_channel_id[instal][\n",
    "                        list_sensor[sensor_number]\n",
    "                    ] = api.get_sensor_channels(\n",
    "                        sensor_type=sensor_type, install=dict_instal_json[instal][\"id\"]\n",
    "                    )\n",
    "\n",
    "                    list_channel_id.extend(\n",
    "                        dict_sensor_channel_id[instal][list_sensor[sensor_number]][dict_sensor_channel_id[instal][list_sensor[sensor_number]][\"deleted_at\"].isna()].index.tolist()\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            sensor_number += 1\n",
    "\n",
    "    dict_instal_logs[instal] = list_sensor_logging  # dict with the list of sensors logging for each installation\n",
    "    dict_channel_id[instal] = list_channel_id       # dict with the list of channels for each installation\n",
    "\n",
    "\n",
    "    # substraction, result is the list of sensors that are not logging, and not deleted from the config\n",
    "    diff_logs[instal] = list(\n",
    "        set(dict_channel_id[instal]) - set(dict_instal_logs[instal])\n",
    "    )\n",
    "\n",
    "# download the logs for the preseries for 1 day\n",
    "with open(installation_path + \"local.json\") as f:\n",
    "    local_data = json.load(f)\n",
    "\n",
    "api_razon = API(local_data[\"API_user\"], local_data[\"API_pwd\"], dev_space=False, install=9)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    start_time = dt.datetime.now() - dt.timedelta(hours=2)\n",
    "    df_razon = api_razon.get_sensors_csv(start=start_time);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 86.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Qair has no ID, please edit the config.json file ⚠️\n",
      "\n",
      "2024-02-07 09h50 - 👤 Insolight\n",
      "\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Installation      | Sensor ID   | Sensor Name                              | Snow fall   | Strong wind    | High temp   | Screen mode             |\n",
      "+===================+=============+==========================================+=============+================+=============+=========================+\n",
      "| Agroscope Series  |             |                                          |             |                |             |                         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Agroscope Berries | 86          | WIND02_EXT                               |             |                |             | screen_zone1: Emergency |\n",
      "|                   | 43          | TRH_top_Insolagrin01_T60_Portrait_EW     |             |                |             | screen_zone2: Emergency |\n",
      "|                   | 44          | TRH_bottom_Insolagrin01_T60_Portrait_EW  |             |                |             | screen_zone3: Emergency |\n",
      "|                   | 45          | TRH_top_Insolagrin02_T40_Portrait_EW     |             |                |             | screen_zone4: Emergency |\n",
      "|                   | 46          | TRH_bottom_Insolagrin02_T40_Portrait_EW  |             |                |             | screen_zone6: Emergency |\n",
      "|                   | 13          | PAR01_Insolagrin01_T60_Portrait_EW       |             |                |             | screen_zone5: Emergency |\n",
      "|                   | 14          | PAR02_Insolagrin01_T60_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 15          | PAR03_Insolagrin01_T60_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 16          | PAR04_Insolagrin01_T60_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 17          | PAR01_Insolagrin02_T40_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 18          | PAR02_Insolagrin02_T40_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 19          | PAR03_Insolagrin02_T40_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 20          | PAR04_Insolagrin02_T40_Portrait_EW       |             |                |             |                         |\n",
      "|                   | 47          | TRH_top_Insolagrin03_T60_Portrait_WW     |             |                |             |                         |\n",
      "|                   | 48          | TRH_bottom_Insolagrin03_T60_Portrait_WW  |             |                |             |                         |\n",
      "|                   | 49          | TRH_top_Insolagrin04_T40_Portrait_WW     |             |                |             |                         |\n",
      "|                   | 50          | TRH_bottom_Insolagrin04_T40_Portrait_WW  |             |                |             |                         |\n",
      "|                   | 21          | PAR01_Insolagrin03_T60_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 22          | PAR02_Insolagrin03_T60_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 23          | PAR03_Insolagrin03_T60_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 24          | PAR04_Insolagrin03_T60_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 25          | PAR01_Insolagrin04_T40_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 26          | PAR02_Insolagrin04_T40_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 27          | PAR03_Insolagrin04_T40_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 28          | PAR04_Insolagrin04_T40_Portrait_WW       |             |                |             |                         |\n",
      "|                   | 11          | PAR01_EXT                                |             |                |             |                         |\n",
      "|                   | 12          | PAR02_EXT                                |             |                |             |                         |\n",
      "|                   | 41          | TRH_top_EXT                              |             |                |             |                         |\n",
      "|                   | 42          | TRH_bottom_EXT                           |             |                |             |                         |\n",
      "|                   | 52          | TRH_bottom_Insolagrin05_T60_Landscape_EW |             |                |             |                         |\n",
      "|                   | 51          | TRH_top_Insolagrin05_T60_Landscape_EW    |             |                |             |                         |\n",
      "|                   | 54          | TRH_bottom_Insolagrin06_T40_Landscape_EW |             |                |             |                         |\n",
      "|                   | 53          | TRH_top_Insolagrin06_T40_Landscape_EW    |             |                |             |                         |\n",
      "|                   | 29          | PAR01_Insolagrin05_T60_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 30          | PAR02_Insolagrin05_T60_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 31          | PAR03_Insolagrin05_T60_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 32          | PAR04_Insolagrin05_T60_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 33          | PAR01_Insolagrin06_T40_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 34          | PAR02_Insolagrin06_T40_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 35          | PAR03_Insolagrin06_T40_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 36          | PAR04_Insolagrin06_T40_Landscape_EW      |             |                |             |                         |\n",
      "|                   | 130         | LeafTemp_Z2_int_int                      |             |                |             |                         |\n",
      "|                   | 131         | LeafTemp_Z2_side_int                     |             |                |             |                         |\n",
      "|                   | 132         | LeafTemp_Z2_side_ext                     |             |                |             |                         |\n",
      "|                   | 137         | LeafTemp_Z4_int_int                      |             |                |             |                         |\n",
      "|                   | 161         | SOIL_UP_Insolagrin02                     |             |                |             |                         |\n",
      "|                   | 162         | SOIL_DOWN_Insolagrin02                   |             |                |             |                         |\n",
      "|                   | 117         | RAIN_EXT                                 |             |                |             |                         |\n",
      "|                   | 71          | WIND01_EXT                               |             |                |             |                         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Bioschmid         |             |                                          |             |                |             | No logs for 2d+         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Etchelecu         |             |                                          |             |                |             | No logs for 2d+         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Qair              |             |                                          |             | 00h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 03h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 06h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 09h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 12h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 15h 09-02-2024 |             |                         |\n",
      "|                   |             |                                          |             | 18h 09-02-2024 |             |                         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n",
      "| Pre-Serie         | 1_1         | Razon_GHI: No logs for > 1d              |             |                |             |                         |\n",
      "+-------------------+-------------+------------------------------------------+-------------+----------------+-------------+-------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for instal in tqdm(dict_instal_json):\n",
    "    #try to identify the missing sensors from the channel list\n",
    "    for sensor_id in diff_logs[instal]:\n",
    "        for sensor in list_sensor:\n",
    "            try:\n",
    "                dict_missing_sensors[sensor_id] = [\n",
    "                    instal,\n",
    "                    dict_sensor_channel_id[instal][sensor]\n",
    "                    .loc[sensor_id]\n",
    "                    .address,\n",
    "                    dict_sensor_channel_id[instal][sensor]\n",
    "                    .loc[sensor_id]\n",
    "                    .sensor_name,\n",
    "                    dict_sensor_channel_id[instal][sensor]\n",
    "                    .loc[sensor_id]\n",
    "                    .channel_name,\n",
    "                ]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "df_missing_sensors = pd.DataFrame.from_dict(\n",
    "    dict_missing_sensors,\n",
    "    orient=\"index\",\n",
    "    columns=[\"installation\", \"address\", \"sensor_name\", \"channel_name\"],\n",
    ")\n",
    "df_missing_sensors = df_missing_sensors.drop_duplicates(subset=[\"sensor_name\"])\n",
    "\n",
    "columns = [\"Installation\", \"Sensor ID\", \"Sensor Name\", \"Snow fall\", \"Strong wind\", \"High temp\", \"Screen mode\"]\n",
    "df_report = pd.DataFrame(columns=columns)\n",
    "\n",
    "dict_alert_time = format_timestamps_in_dict(dict_alert_time)\n",
    "\n",
    "# fill the report with the missing sensors dict, with one line per installation, and a list of the missing sensors\n",
    "for instal in dict_instal_json:\n",
    "    df_report.loc[instal, (\"Installation\")] = instal\n",
    "    df_report.loc[instal, (\"Sensor ID\")] = df_missing_sensors[\n",
    "        df_missing_sensors[\"installation\"] == instal\n",
    "    ].address.to_list()\n",
    "    df_report.loc[instal, (\"Sensor Name\")] = df_missing_sensors[\n",
    "        df_missing_sensors[\"installation\"] == instal\n",
    "    ].sensor_name.to_list()\n",
    "    df_report.loc[instal, (\"Snow fall\")] = dict_alert_time[instal][\"Snow fall\"]\n",
    "    df_report.loc[instal, (\"Strong wind\")] = dict_alert_time[instal][\"Strong wind\"]\n",
    "    df_report.loc[instal, (\"High temp\")] = dict_alert_time[instal][\"High temperature\"]\n",
    "    df_report.loc[instal, (\"Screen mode\")] = dict_screen_states[instal]\n",
    "df_report = df_report.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#make a copy of the report dataframe to convert the lists to strings, so that it can be printed\n",
    "df_report_string = df_report.copy()\n",
    "\n",
    "# convert the lists to strings\n",
    "for col in df_report_string.columns:\n",
    "    if col == \"Installation\":\n",
    "        continue\n",
    "    df_report_string[col] = df_report_string[col].apply(list_to_string)\n",
    "\n",
    "\n",
    "# add the Razon to the report\n",
    "if len(df_razon[df_razon[\"Identifier\"] == \"1_1\"]):\n",
    "    # print(\"Razon has been logging\")\n",
    "    last_log_razon = df_razon[df_razon[\"Identifier\"] == \"1_1\"].index[-1]\n",
    "    now_timestamp = pd.Timestamp.now(tz=\"UTC\")\n",
    "    time_diff_razon = now_timestamp - last_log_razon\n",
    "    # print(f\"Time since last log: {time_diff_razon}\")\n",
    "    if time_diff_razon > pd.Timedelta(minutes=20):\n",
    "        # time_diff_razon.strftime(\"%d %H:%M:%S\")\n",
    "        time_diff_razon = time_diff_razon.floor(\"T\")\n",
    "        df_report_string.loc[len(df_report)] = [\"Pre-Serie\", \"1_1\", f\"Razon_GHI: {time_diff_razon}\", \"\", \"\", \"\", \"\"]\n",
    "    else:\n",
    "        df_report_string.loc[len(df_report)] = [\"Pre-Serie\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "else:\n",
    "    df_report_string.loc[len(df_report)] = [\"Pre-Serie\", \"1_1\", \"Razon_GHI: No logs for > 2h\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "\n",
    "\n",
    "save_alerts_to_csv(df_report_string.copy())\n",
    "\n",
    "no_weather_data = \"\"\n",
    "loc_no_weather = \"\"\n",
    "for instal in dict_instal_json:\n",
    "    if dict_weather_data[instal][\"list\"][0][\"dt\"] == 0:\n",
    "        no_weather_data = \"\\n⚠️ no weather data available for \"\n",
    "        loc_no_weather = loc_no_weather + instal + \", \"\n",
    "if len(no_weather_data) > 0:\n",
    "    print(no_weather_data + loc_no_weather[:-2] + \"\\n\")\n",
    "\n",
    "for instal in dict_instal_json:\n",
    "    if dict_instal_json[instal][\"id\"] == \"xx\":\n",
    "        name = dict_instal_json[instal][\"name\"]\n",
    "        print(f\"\\n⚠️ {name} has no ID, please edit the config.json file ⚠️\\n\")\n",
    "\n",
    "try:\n",
    "    username = getpass.getuser()\n",
    "except:\n",
    "    username = \"xx\"\n",
    "print(str(pdl.now().strftime(\"%Y-%m-%d %Hh%M\")) + f\" - 👤 {getpass.getuser()}\" +\"\\n\")\n",
    "print(tabulate(df_report_string, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "with open(\"reports/output.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(str(pdl.now().strftime(\"%Y-%m-%d %Hh%M\")) + f\" - 👤 {getpass.getuser()}\" +\"\\n\\n\")\n",
    "    text_file.write(tabulate(df_report_string, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    text_file.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:51<00:00, 10.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data...\n",
      "\n",
      "Agroscope Series\n",
      "+-----------------------------------+------------+---------------------+--------------+\n",
      "|                                   | Last log   | Time offline (1w)   | % offline    |\n",
      "|-----------------------------------+------------+---------------------+--------------|\n",
      "| TRH02_GT_tunnel                   | Online     | 0 days 00:14:32     | [----------] |\n",
      "| TRH01_GT_tunnel                   | Online     | 0 days 00:14:32     | [----------] |\n",
      "| TRH01_GT1_tunnel                  | Online     | 0 days 00:11:32     | [----------] |\n",
      "| TRH_bottom_Nursery                | Online     | 0 days 00:08:32     | [----------] |\n",
      "| TRH02_GT1_tunnel                  | Online     | 0 days 00:08:32     | [----------] |\n",
      "| wind_speed_ultrasonic             | Online     | 0 days 00:06:00     | [----------] |\n",
      "| PAR4                              | Online     | 0 days 00:05:32     | [----------] |\n",
      "| PAR3                              | Online     | 0 days 00:05:32     | [----------] |\n",
      "| PAR2                              | Online     | 0 days 00:05:32     | [----------] |\n",
      "| PAR1                              | Online     | 0 days 00:05:32     | [----------] |\n",
      "| TRH_top_Nursery                   | Online     | 0 days 00:05:32     | [----------] |\n",
      "| TRH01_TX_tunnel                   | Online     | 0 days 00:05:32     | [----------] |\n",
      "| T_RH_umbrella_bottom              | Online     | 0 days 00:05:32     | [----------] |\n",
      "| T_RH_umbrella_top                 | Online     | 0 days 00:05:32     | [----------] |\n",
      "| weather_station                   | Online     | 0 days 00:03:00     | [----------] |\n",
      "| wind_speed                        | Online     | 0 days 00:03:00     | [----------] |\n",
      "| PAR_EXT_06                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_EXT_05                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_EXT_04                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR01_Nursery                     | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR01_GT1_tunnel                  | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR01_GT_tunnel                   | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR01_TX_tunnel                   | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_umbrella                      | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_umbrella_strawb               | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_STRAWB                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR_ext_bis                       | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR8                              | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR7                              | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR6                              | Online     | 0 days 00:02:32     | [----------] |\n",
      "| PAR5                              | Online     | 0 days 00:02:32     | [----------] |\n",
      "| GHI_EXT_04                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| GHI_EXT_03                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| GHI_EXT_02                        | Online     | 0 days 00:02:32     | [----------] |\n",
      "| T_RH_ext_bottom                   | Online     | 0 days 00:02:32     | [----------] |\n",
      "| T_RH2                             | Online     | 0 days 00:02:32     | [----------] |\n",
      "| T_RH1                             | Online     | 0 days 00:02:32     | [----------] |\n",
      "| TRH_EXT_top                       | Online     | 0 days 00:02:32     | [----------] |\n",
      "| GHI_EXT                           | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Tulameen_E_NurseryTunnel | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Tulameen_W_NurseryTunnel | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Vajolet_E_NurseryTunnel  | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Vajolet_W_NurseryTunnel  | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Tulameen_E_Nursery       | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Tulameen_W_Nursery       | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Vajolet_E_Nursery        | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp_Vajolet_W_Nursery        | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp02_Joly_Insolagrin05_TX   | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp01_Joly_Insolagrin05_TX   | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp02_Flair_Insolagrin05_TX  | Online     | 0 days 00:00:00     | [----------] |\n",
      "| LeafTemp01_Flair_Insolagrin05_TX  | Online     | 0 days 00:00:00     | [----------] |\n",
      "| leaf_temp_umbrella1               | Online     | 0 days 00:00:00     | [----------] |\n",
      "| leaf_temp_insolagrin_1            | Online     | 0 days 00:00:00     | [----------] |\n",
      "+-----------------------------------+------------+---------------------+--------------+\n",
      "\n",
      "\n",
      "Agroscope Berries\n",
      "+------------------------------------------+------------+---------------------+--------------+\n",
      "|                                          | Last log   | Time offline (1w)   | % offline    |\n",
      "|------------------------------------------+------------+---------------------+--------------|\n",
      "| TRH_bottom_Insolagrin03_T60_Portrait_WW  | Online     | 5 days 21:12:00     | [########--] |\n",
      "| WIND02_EXT                               | Online     | 5 days 15:20:00     | [########--] |\n",
      "| TRH_top_Insolagrin02_T40_Portrait_EW     | Online     | 2 days 23:14:00     | [####------] |\n",
      "| TRH_bottom_Insolagrin01_T60_Portrait_EW  | Online     | 2 days 23:12:00     | [####------] |\n",
      "| TRH_top_Insolagrin04_T40_Portrait_WW     | Online     | 2 days 22:40:00     | [####------] |\n",
      "| TRH_top_Insolagrin01_T60_Portrait_EW     | Online     | 2 days 22:40:00     | [####------] |\n",
      "| TRH_top_Insolagrin03_T60_Portrait_WW     | Online     | 2 days 22:38:00     | [####------] |\n",
      "| TRH_bottom_Insolagrin06_T40_Landscape_EW | Online     | 2 days 22:18:00     | [####------] |\n",
      "| TRH_top_Insolagrin06_T40_Landscape_EW    | Online     | 2 days 22:06:00     | [####------] |\n",
      "| TRH_bottom_Insolagrin04_T40_Portrait_WW  | Online     | 2 days 22:06:00     | [####------] |\n",
      "| TRH_bottom_Insolagrin02_T40_Portrait_EW  | Online     | 2 days 22:06:00     | [####------] |\n",
      "| PAR04_Insolagrin06_T40_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin06_T40_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin06_T40_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin06_T40_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR04_Insolagrin05_T60_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin05_T60_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin05_T60_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin05_T60_Landscape_EW      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_EXT                                | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_EXT                                | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR04_Insolagrin04_T40_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin04_T40_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin04_T40_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin04_T40_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR04_Insolagrin03_T60_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin03_T60_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin03_T60_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin03_T60_Portrait_WW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR04_Insolagrin02_T40_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin02_T40_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin02_T40_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin02_T40_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR04_Insolagrin01_T60_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR03_Insolagrin01_T60_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR02_Insolagrin01_T60_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| PAR01_Insolagrin01_T60_Portrait_EW       | Online     | 2 days 22:03:00     | [####------] |\n",
      "| SOIL_DOWN_Insolagrin02                   | Online     | 2 days 22:03:00     | [####------] |\n",
      "| SOIL_UP_Insolagrin02                     | Online     | 2 days 22:03:00     | [####------] |\n",
      "| TRH_top_Insolagrin05_T60_Landscape_EW    | Online     | 2 days 22:03:00     | [####------] |\n",
      "| TRH_bottom_Insolagrin05_T60_Landscape_EW | Online     | 2 days 22:03:00     | [####------] |\n",
      "| TRH_bottom_EXT                           | Online     | 2 days 22:03:00     | [####------] |\n",
      "| TRH_top_EXT                              | Online     | 2 days 22:03:00     | [####------] |\n",
      "| RAIN_EXT                                 | Online     | 2 days 22:03:00     | [####------] |\n",
      "| WIND01_EXT                               | Online     | 2 days 22:03:00     | [####------] |\n",
      "| LeafTemp_Z4_int_int                      | Online     | 2 days 22:03:00     | [####------] |\n",
      "| LeafTemp_Z2_side_ext                     | Online     | 2 days 22:03:00     | [####------] |\n",
      "| LeafTemp_Z2_side_int                     | Online     | 2 days 22:03:00     | [####------] |\n",
      "| LeafTemp_Z2_int_int                      | Online     | 2 days 22:03:00     | [####------] |\n",
      "+------------------------------------------+------------+---------------------+--------------+\n",
      "\n",
      "\n",
      "Bioschmid\n",
      "+------------------+------------+---------------------+--------------+\n",
      "|                  | Last log   | Time offline (1w)   | % offline    |\n",
      "|------------------+------------+---------------------+--------------|\n",
      "| WIND02_EXT       | Online     | 4 days 08:22:00     | [######----] |\n",
      "| PAR01_EXT        | Online     | 2 days 15:33:00     | [####------] |\n",
      "| PAR02_EXT        | Online     | 0 days 07:29:00     | [----------] |\n",
      "| TRH02_EXT        | Online     | 0 days 02:26:00     | [----------] |\n",
      "| TRH04_EXT        | Online     | 0 days 02:10:00     | [----------] |\n",
      "| TRH02_kontroll   | Online     | 0 days 01:10:00     | [----------] |\n",
      "| TRH01_EXT        | Online     | 0 days 00:55:00     | [----------] |\n",
      "| TRH01_agriverti  | Online     | 0 days 00:34:00     | [----------] |\n",
      "| TRH01_INSOLAGRIN | Online     | 0 days 00:34:00     | [----------] |\n",
      "| TRH02_INSOLAGRIN | Online     | 0 days 00:28:00     | [----------] |\n",
      "| PAR04_INSOLAGRIN | Online     | 0 days 00:24:00     | [----------] |\n",
      "| PAR03_INSOLAGRIN | Online     | 0 days 00:24:00     | [----------] |\n",
      "| PAR02_INSOLAGRIN | Online     | 0 days 00:24:00     | [----------] |\n",
      "| PAR01_INSOLAGRIN | Online     | 0 days 00:24:00     | [----------] |\n",
      "| GHI_01_EXT       | Online     | 0 days 00:24:00     | [----------] |\n",
      "| RAIN01_EXT       | Online     | 0 days 00:24:00     | [----------] |\n",
      "| WIND01_EXT       | Online     | 0 days 00:24:00     | [----------] |\n",
      "| TRH02_agriverti  | Online     | 0 days 00:18:00     | [----------] |\n",
      "| TRH03_EXT        | Online     | 0 days 00:06:00     | [----------] |\n",
      "| PAR03_agriverti  | Online     | 0 days 00:05:00     | [----------] |\n",
      "| PAR02_agriverti  | Online     | 0 days 00:05:00     | [----------] |\n",
      "| PAR01_agriverti  | Online     | 0 days 00:05:00     | [----------] |\n",
      "| TRH01_kontroll   | Online     | 0 days 00:02:39     | [----------] |\n",
      "| PAR03_kontroll   | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR02_kontroll   | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR01_kontroll   | Online     | 0 days 00:00:00     | [----------] |\n",
      "+------------------+------------+---------------------+--------------+\n",
      "\n",
      "\n",
      "Etchelecu\n",
      "+-----------------------+------------+---------------------+--------------+\n",
      "|                       | Last log   | Time offline (1w)   | % offline    |\n",
      "|-----------------------+------------+---------------------+--------------|\n",
      "| TRH_bottom_Insolagrin | Online     | 0 days 00:46:00     | [----------] |\n",
      "| TRH_bottom_EXT        | Online     | 0 days 00:06:00     | [----------] |\n",
      "| TRH_bottom_control    | Online     | 0 days 00:03:00     | [----------] |\n",
      "| PAR02_control         | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR01_control         | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR02_EXT             | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR01_EXT             | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR04_Insolagrin      | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR03_Insolagrin      | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR02_Insolagrin      | Online     | 0 days 00:00:00     | [----------] |\n",
      "| PAR01_Insolagrin      | Online     | 0 days 00:00:00     | [----------] |\n",
      "| GHI_01_EXT            | Online     | 0 days 00:00:00     | [----------] |\n",
      "| TRH_top_control       | Online     | 0 days 00:00:00     | [----------] |\n",
      "| TRH_top_EXT           | Online     | 0 days 00:00:00     | [----------] |\n",
      "| TRH_top_Insolagrin    | Online     | 0 days 00:00:00     | [----------] |\n",
      "| RAIN_EXT              | Online     | 0 days 00:00:00     | [----------] |\n",
      "| WIND02_EXT            | Online     | 0 days 00:00:00     | [----------] |\n",
      "| WIND01_EXT            | Online     | 0 days 00:00:00     | [----------] |\n",
      "+-----------------------+------------+---------------------+--------------+\n",
      "\n",
      "\n",
      "Qair\n",
      "+------------+---------------------+-------------+\n",
      "| Last log   | Time offline (1w)   | % offline   |\n",
      "|------------+---------------------+-------------|\n",
      "+------------+---------------------+-------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the last logs for each installation and sensor\n",
    "logs_joined_unique = last_logs(dict_instal_json, list_sensor, api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataViz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
